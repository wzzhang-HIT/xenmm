% xen memory management experiment paper
% xiehuc

实验环境
=======

程序配置环境
-----------

程序集分为两个部分.服务端和客户端.是典型的C/S架构.
只不过.这里我们的服务器和客户机分别运行于物理机和虚拟机.
另外程序集附带了4个辅助测试程序.方便测试和记录数据.

- **mmclient** : 客户程序.每间隔1秒种.读取虚拟机`总内存`,`使用内存`,`可用内存`,并写入xenstorage中.
- **mmserver** : 服务程序.每间隔1秒种.读取所有虚拟机的xenstorage结点.取得内存信息.并且进行矩阵运算.
  然后将结果作为最后的分配方案.修改各个虚拟机的内存分配.
- **mm_test_static** : 该程序能够申请一块内存区域.并且保持.并且定时写入.防止被替换到swap分区.
  在模拟负载环境中使用.
- **mm_test_mono**   : 该程序能够指定一个范围.并且从低到高的提出内存申请.再由高到低的释放内存.
  在mono测试中使用.
- **mm_test_random** : 该程序能够指定一个范围和时间间隔.在时间间隔以内提出随机大小的内存申请.
  在整个测试中没有使用.
- **mm_util_swap**   : 该程序能够定时的记录swap使用率.在dacapo测试中使用.

另外.还使用了2个测试标准:

- **dacapo** : [link](http://dacapobench.org/)

物理机环境
----------

物理机使用曙光的64核服务器.具体的信息如下:

key          value
----------   ---------------------------------
vendor_id     AuthenticAMD
model name    AMD Opteron(TM) Processor 6272
cpu MHz       2100.108
cache size    2048KB
count         64
-----------------------------------------------
Table: Cpu Info


内存信息:

key            value
-----------    ------------------------------
Total Width    72 bits
Data Width     64 bits
Size           4096 MB
Form Factor    DIMM
Locator        DIMM11
Bank Locator   BANK11
Type           DDR3
Type Detail    Synchronous
Speed          1333 MHz
Count          32
Total          128GB
----------------------------------------------
Table: Memory Info

系统使用Ubuntu 12.04 Desktop 64位.`uname -r`信息如下:

Linux root3-Server 3.2.0-29-generic #46-Ubuntu SMP Fri Jul 27 17:03:23 UTC 2012 x86_64 x86_64 x86_64 GNU/Linux

xen套件使用4.1.2版本.从Ubuntu软件中心中取得.
具体信息用`xm info`如下:

key                    value
-------------          -------------------------------------------
host                    root3-Server
release                 3.2.0-29-generic
version                 #46-Ubuntu SMP Fri Jul 27 17:03:23 UTC 2012
machine                 x86_64
nr_cpus                 64
nr_nodes                8
cores_per_socket        16
threads_per_core        1
cpu_mhz                 2100
virt_caps               hvm
total_memory            131054
free_memory             17
free_cpus               0
xen_major               4
xen_minor               1
xen_extra               .2
xen_scheduler           credit
xen_pagesize            4096
platform_params         virt_start=0xffff800000000000
xen_changeset           unavailable
xen_commandline         placeholder
cc_compiler             gcc version 4.6.3 (Ubuntu/Linaro 4.6.3-1ubuntu5) 
cc_compile_by           marc.deslaurier
cc_compile_domain       ubuntu.com
cc_compile_date         Tue Dec 11 16:32:07 UTC 2012
xend_config_format      4
----------------------------------------------------------
Table: xm info


虚拟机
------

5台虚拟机均使用同一规格:  
系统使用Ubuntu 12.10 Server版本.没有X环境.

* CPU: 同物理机.只分配一个核心
* Mem: 1024MB
* MaxMem: 2048MB
* System: Ubuntu Server
* uname: Linux ubuntu 3.5.0-17-generic #28-Ubuntu SMP Tue Oct 9 19:31:23 UTC 2012 x86_64 GNU/Linux
* 虚拟化: 全虚拟化

实验过程
=======

基本操作
-------

* 在虚拟机停机的时候设置好maxmem.该值作为实际内存分配上界.具有高优先级.
 当分配的值超过maxmem之后.实际分配的结果是maxmem.
 可以用`xm mem-max`设置,或者是virt-manager.
 max值只能在停机的时候设置,在运行的时候设置下次启动有效.

* 在虚拟机之中开启client
 因为有脚本.所以就很方便了.
	$ sudo service mmclientd start
 需要注意的是xenstorage服务需要指明xenbus系统设备的路径.
 因为xenstorage服务实际上是封装的对xenbus的文件操作.
 许多虚拟机环境没有初始化好这个值.导致启动失败.
 所以脚本中通过变量的方式指明了路径.xenbus常见的路径是/dev/xen/xenbus或/proc/xen/xenbus.
 需要根据虚拟机的实际路径修改脚本中的变量.

* 在服务器上运行调节程序
 如果是通过编译源代码的方式.使用`make install`安装到系统中了.
 	$ sudo mmserver
 如果是只是编译了.而没有安装.进入编译目录.执行
	$ sudo ./src/mmserver
 之后可以在控制台中看到输出.并且在当前文件夹中可以看到log文件.
 log文件的命名规则是:日期_实验次数_[虚拟机id].log
 次数在这一天之中做试验的次数.如果做了两次试验,那么
 次数有1和2.2是最近做的试验.所以所测试的日志文件不会被覆盖.
 有了数据了.我们通过Mathematica绘制图型.当然.类似的工作也可以由matlab或者gnuplot完成.

$\tau$值的推导与测定
==================

求解线性方程组
------------

现在先不考虑交换空间.这可以通过假设只研究总内存能够满足分配方案的情况.此时交换空间使用率为0.
即可以满足不用考虑的条件.

原方程组可以重新用矩阵表达:
	$$AX=B$$

其中$A$为
	$\left(
	\begin{array}{ccccc}
	 1 & 1 & 1 &  & 1 \\
	 1 & -1 & 0 & \cdots  & 0 \\
	 1 & 0 & -1 &  & 0 \\
	  & \vdots  & & \ddots &  \\
	 1 & 0 & 0 &  & -1 \\
	\end{array}
	\right)$
,B为
	$\left(
	\begin{array}{c}
	 N \\
	 \tau  \left(A_1-A_2\right) \\
	 \tau  \left(A_1-A_3\right) \\
	 \vdots  \\
	 \tau  \left(A_1-A_n\right) \\
	\end{array}
	\right)$
.n为方程的个数.
X为
	$\left(
	\begin{array}{c}
	 N_{\text{t1}} \\
	 N_{\text{t2}} \\
	 N_{\text{t3}} \\
	 \vdots  \\
	 N_{\text{tn}} \\
	\end{array}
	\right)$

现,为了表述方便.左右两边同时除以$N$,使得单位化为1.即$\frac{A X}{N}=\frac{B}{N}$.
解得X为$A^{-1} B$即
	$A^{-1} B$
=
	$\left(
	\begin{array}{ccccc}
	 \frac{1}{n} & \frac{1}{n} & \frac{1}{n} &  & \frac{1}{n} \\
	 \frac{1}{n} & \frac{1}{n}-1 & \frac{1}{n} & \cdots  & \frac{1}{n} \\
	 \frac{1}{n} & \frac{1}{n} & \frac{1}{n}-1 &  & \frac{1}{n} \\
		         & \vdots      &               & \ddots &  \\
	 \frac{1}{n} & \frac{1}{n} & \frac{1}{n} &          & \frac{1}{n}-1 \\
	\end{array}
	\right)$
	$\left(
	\begin{array}{c}
	 1 \\
	 \tau  \left(A_1-A_2\right) \\
	 \tau  \left(A_1-A_3\right) \\
	 \vdots  \\
	 \tau  \left(A_1-A_n\right) \\
	\end{array}
	\right)$
=
	$\left(
	\begin{array}{c}
	 \tau \left(A_1-\frac{\sum _{i=1}^n A_i}{n}\right)+\frac{1}{n} \\
	 \tau  \left(A_2-\frac{\sum _{i=1}^n A_i}{n}\right)+\frac{1}{n} \\
	 \tau  \left(A_3-\frac{\sum _{i=1}^n A_i}{n}\right)+\frac{1}{n} \\
	 \vdots  \\
	 \tau  \left(A_n-\frac{\sum _{i=1}^n A_i}{n}\right)+\frac{1}{n} \\
	\end{array}
	\right)$

设A={$A_1$,$A_2$,$A3$,$\dots$,$A_n$}.为整个系统当前使用的内存的集合
其中,当$A_i(i=1 \ldots n)$固定的时候.$\frac 1 n \sum _{i=1}^n A_i$为定值.等于$\bar{A}$

所以对于$N_{ti}$可以重新表述为.所有内存的平均+当前内存和总的使用内存的平均的差值再乘以一个影响系数.
该方程关于$\tau$是一个线性方程.线性变化的.当前内存$A_i$和$\bar A$的差值要么为正要么为负.乘上$\tau$之后都不改变极性.只会改变幅值.
幅度范围以$\frac 1 n$为中心.上下伸展.

$\tau$的值域的讨论
-----------------

当0<$\tau$<1时.和$\tau$=1相比实际上是拉小这种差异性.
$\tau$为0的时候.所有解都取得$\frac 1 n$.$\tau$为1的时候差异性最大.
当$\tau$>1时.实际上是拉大这种差异性.但是会因为幅度范围到达负值.也就是一些情况.会分配负的内存.所以是不可取的.
所以$\tau$的取值范围是(0,1]

现在以n=2作出图形,任意取$A_1$和$A_2$.(这里取$A_1=0$,$A_2=1$).

![受$\tau$影响的结果范围](graph/tau_plot.png)

可以看出这种变化趋势.

$\tau$的可行解域的讨论
---------------------

为了研究不同的$\tau$值的影响.现在我们来从下面一个角度观察.
 >  在总内存能够满足分配的情况下.需要解X的每一个元素$N_{ti}$大于等于当前申请的量$A_i$
 >  也就是分配的结果应该大于申请的容量.
 >  否则.会得出明明还有富余但是分配的反而无法满足提出的需求.这种异常的情况.

所以可以列出条件限制方程组 $X\geq A$ 即
$\begin{array}{c}
 N_{\text{t1}}\geq A_1   \\
 N_{\text{t2}}\geq A_2   \\
 \vdots    \\
 N_{\text{tn}}\geq A_n   \\
\end{array}$
最后根据$\tau$画出来解区域.称这样的区域为可行解域.

为了方便研究.只画出在n=2时不同$\tau$的可行解域.

![](graph/valid_region_0.png)

这个是$\tau$等于0的时候的结果.可以看到.其中满足解的范围非常小.
特别的.总内存为1,每台虚拟机在初始化的时候各自分配0.5.
要求$A_1,A_2 \leq 0.5$.也就是每台虚拟机只能提出小于等于各自的初始内存.不能超过它.不然解就会违反判定条件.
这个是非常的不合理的.而且是毫无意义的.

下面再看一下$\tau$从0取到1,间隔0.2的情况

![](graph/valid_region_table.png)

由组图可以看出随着$\tau$的增大.可行解域也不断增大.
具体来说.不可解的例子,如取$\tau=0.8$的图,取$A_1=0.8,A_2=0.2$.求解得到
X={0.74,0.26}对于$A_1$就出现了异常解.

当$\tau$为1的时候达到最大,满足可分配条件的全域($A_1+A_2<1$)可解

综上所述:
从理论角度上考虑,$\tau$=1是一个比较好的取值.

系统负载性能测试
=============

**在测试之前.将$\tau$值设置为1.**

一般性测试.
----------

首先使用mono程序进行简单的测试工作.目的是为了观察一下分配的有效性.
首先简单的开启了两太虚拟机.在其中一台上面执行mono程序.  
参数设置为从50M到400M.  
在物理机端记录数据绘制图形如下:

![](graph/mono_2.png)

从图中可以得出:随着使用量的增大.调节程序从空闲机器中取走一部分内存.
给了负载机.而且取走的内存并不严格等于请求的内存.因为负载机的可用内存也在减小.
这个就是由$\tau$值控制的.

再将虚拟机的数量增加到5台,记录数据如下:

![](graph/mono_5.png)

从结果可以看到.和上一个实验类似,4台空闲机的总内存都有微小的下降.
这是因为.经过调节之后.从4台空闲机上均分了1台负载机的内存要求.

负载性测试
---------

dacapo是一套用java写成的测试集.利用真实的程序.测试结果能够比较好的体现
物理世界的真实负载.测试集有很多.有一些是CPU集中型的.一些是内存集中型的.
以下是dacapo的测试表.

-----------------------------------------------------------------
     testset     description
------------     -------------------------------------------------
avrora           模拟一组程序在AVR微控制器上运行

batik            根据Apache的Batik产生一组SVG图像

eclipse          为Eclipse IDE执行一些非GUI的jdt性能测试

fop              分析和格式化XSL-FO文件,并生成PDF文件

h2               执行类似于JDBCbench的内存评估,执行一组和
                 银行程序模型相关的事务.代替了旧的hsqldb测试

jython           pybench 一个Python的评估解释器.

luindex          使用lucene来建立一些文件的索引;是莎士比亚
                 和King James Bible的作品

lusearch         使用lucene来做一些文本搜索;基于莎士比亚和
                 King James Bible作品中的一些词语

pmd              分析一些Java的Classes文件,检查一些源代码问题.

sunflow          使用光线追踪渲染一些图片

tomcat           运行一些Tomcat服务器的检索和验证网页结果的查询.

tradebeans       通过jave beans运行DayTrader基准测试
                   与H2作为内存中的Geronimo后端
                   底层数据库

tradesoap        通过soap运行DayTrader基准测试
                   与H2作为内存中的Geronimo后端
                   底层数据库

xalan            把XML转换成HTML
-------------------------------------------------------------------
Table: dacapo testset


首先是低负载环境的测试,低负载是和高负载对应的.是通过**不**执行额外的程序来模拟的.

实验结果
======

实验3:dacapo
-----------

**参数**:低负载,开启调节和不开启调节

![低负载调节效果对比](graph/dacapo_low_bar.png)

由图中得出.在低负载情况下.无论是否开启内存.对CPU影响都不大.
都能够保持高效的运算.

实验4:dacapo
------------

**参数**:高负载(800M),开启调节和不开启调节

![高负载调节效果对比](graph/dacapo_high_bar.png)

由图中看出.在高负载情况下.开启调节能够大幅度的减少执行时间.
和上图对比,完全来说.是在高负载情况下.程序执行时间大幅增加.而经过调节程序.
能够减缓这种增加趋势.在所有测试中.差距明显的是
eclipse,h2,trade beans,trade scope,xalan.
通过附录中对dacapo测试表格的描述可以知道.这些都是内存集中型的.
而CPU集中型的.差距都不是很明显.基本可以忽略.

为了更好的探究其中的原因.参见下图:

![开启调节和不开启调节SWAP占用率](graph/swap_useage.png)

其中蓝色的线条是不开启调节时候.SWAP的占用率.而下面不是非常明显的红色的线条
是开启调节时候的SWAP占用率.
该图有以下的解读:
* 红色的线条比蓝色的短:

>说明开启调节后测试所需要的时间比不开启的短.因为记录是相同的单位时间.
>记录是在测试执行完之后就关闭了.记录的数量少,则总时间就短.
>这个结论和上图中内存集中型测试耗时更少是一致的.

* 红色线条基本没有变化:

>说明开启调节后SWAP分区基本没有使用增加.这个和图1进行参考.知道了因为调节
>程序为负载机分配了更多的内存.使得虽然负载机可用内存依然减少了.但是还完全
>不需要使用SWAP分区.

* 蓝色线条变化剧烈:

>说明不开启调节巨量的使用SWAP分区.因为负载程序的参数是800M.内存一共1000M,
>系统使用100多M.剩下的不足60M.也就是说,负载机已经完全没有什么内存空间执行
>dacapo测试了.所以这个时候只能全部的向SWAP分区申请空间来运行dacapo.

* 不开启调节大量使用SWAP:

>由上面3条结论.我们不难得出负载机器在高负载情况下.开启调节和不开启调节.
>对于内存集中型测试运行时间差异巨大的真正原因:
>不开启调节的时候大量使用SWAP分区.开启调节不用使用SWAP分区.
>SWAP分区的访问速度等于磁盘的访问速度是和内存的访问速度完全不是一个数量级.
>所以导致了不开启调节的时候.消耗时间巨幅增加.

为了探究在开启调节后.负载机没有使用SWAP分区的原因.
参见下图:

![开启调节后所有虚拟机的内存分配](graph/totmem.png)

该图是在调节时候调节程序记录下来的对所有内存的分配.
等效于实验2中.5个虚拟机的总内存变化曲线的集合.
其中非常突出的曲线是负载机的内存变化.非常的夸张.
剩下4条比较相近的是4台空闲机的内存变化.
中间的分割线是10^6KB,也就是1000MB.

该图时间序有3个阶段:

* 开启调节程序`mm_server`
  此时,经过短暂的震荡,内存数值由调节程序接管.
  调节程序通过各个虚拟机的使用量,计算并赋予新的内存分配.
  负载机内存变化到800M(因为此时刚刚运行完无调节的测试,
  系统内存全部释放完了.所以系统内存只使用了100MB,而其他空闲机.
  系统保持一定的缓存,均在200MB~300MB之间)
* 开启负载程序`mm_test_static 800M`
  此时.负载机器内存很快到达1400MB.并维持不变.
  其他各个机器内存使用均跌至950MB.
  负载机增量$1400-800=600$.
  空闲机负增量$(1100-950)*4=600$.所以也是平衡的.虽然从图上.
  有些视错觉.
* 开启dacapo测试程序.
  经过短暂的时间.是人工反应时间.是测试者从开启负载程序到开启
  dacapo测试程序的自然时间.然后在长时间的范围上.都是dacapo的运行
  时间.而且结合图3,内存分配图上.有一个非常明显的特点.
  就是开启调节时候总内存分配图趋势和不开启调节时候SWAP占用率.
  两者是惊人的一致.
  事实上开启调节时候.负载机总内存的分布有以下关系
  $$总内存=系统占用内存+负载程序内存+dacapo运行内存+剩余内存$$
  其中因为是高负载.系统把所有缓存都让出来了.系统占用内存约为100MB且不变.
  负载程序内存是固定的800M.
  剩余内存不多.大概为60M.dacapo运行内存就是如同图上的波动.随时间变化.
  不恒定.
  SWAP空间在开启调节时候基本没有使用.所以不作考虑.
  另外.我们也可以得出结论:
    + 不开启调节时候SWAP占用量和开启调节时候总内存分配趋势一致.
      换一种说法.总内存扣除负载程序内存和系统占用内存和剩余内存
      基本上等于不开启调节时候的SWAP占用量.
    + 开启调节以后因为调节程序为负载机分配了足量的内存.以至于负载机可以
      不必使用SWAP分区.亦即大幅度的抑制性能的损失.
      在调节过程中.4台空闲机的内存变化和负载机的内存变化基本反比一致.
  并且4台空闲机变化一致.这个和图1,图2的结论是一致的.
  综上:我们最终能够描绘内存的移动:
    + 不开启调节情况下:系统和负载程序基本把总内存占用完了.
      dacapo运行必须借助于SWAP分区.
    + 开启调节情况下:系统和负载程序基本把总内存占用完了的时候.
      调节程序又从其他空闲机器中抽走了内存.并补充给负载机器足
      量内存.所以在dacapo运行时候可以不用使用SWAP分区.所以可以
      减少性能的损失.
* dacapo测试运行完成
  此时,总内存分配再次回到1500MB水平并持续.至于为什么不是
  1400MB.因为负载机并不能完全回到之前的完全一致的条件.
  在开始的时候内存使用量为900MB,结束测试后,内存使用量为1200MB
* 关闭负载程序
  此时负载机内存使用量迅速跌至1050MB左右.同时,其他空闲机的内存
  也恢复至同样的水平.此后很长时间保持不变.


